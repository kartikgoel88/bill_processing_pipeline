# Employee Reimbursement Processing Pipeline - Environment Example
# Copy to .env and fill in values

# Input (root folder with structure expense_type/employee_id/bills)
INPUT_ROOT=./test_input
# Optional: PDF to extract policy limits from (overrides defaults when present)
# POLICY_PDF_PATH=test_input/policy/company_policy.pdf
DRY_RUN=false

# LLM endpoint (default: local Ollama; or use https://api.openai.com/v1 for OpenAI)
LLM_BASE_URL=http://localhost:11434/v1
LLM_API_KEY=

# Optional: use different endpoints for vision vs decision (e.g. vision=OpenAI, decision=local)
# Leave unset to use LLM_BASE_URL and LLM_API_KEY for both
LLM_VISION_BASE_URL=
LLM_VISION_API_KEY=
LLM_DECISION_BASE_URL=
LLM_DECISION_API_KEY=

# Model names (Ollama: llava, llama3.2, qwen2.5:7b; OpenAI: gpt-4o-mini)
LLM_VISION_MODEL=llava
LLM_DECISION_MODEL=qwen2.5:7b

# Extraction strategy: fusion (default) | vision_first
# fusion = run OCR + vision, then fuse (current behaviour)
# vision_first = try Donut/LayoutLMv3/Qwen-VL/vision_llm first; use Tesseract only as fallback
EXTRACTION_STRATEGY=vision_first

# Vision/document extraction: donut (default) | vision_llm | layoutlm | qwen_vl
# donut = Donut model (no vision LLM; requires pip install -e ".[document]")
# vision_llm = vision LLM (Ollama/OpenAI-compatible)
# layoutlm = LayoutLMv3 token classification (uses Tesseract for word boxes)
# qwen_vl = Qwen-VL via vision API (set QWEN_VL_MODEL below or use LLM_VISION_MODEL)
VISION_EXTRACTOR=qwen_vl

# Qwen-VL model name (when VISION_EXTRACTOR=qwen_vl or when comparing extractors). Ollama: use qwen2.5vl (pull with: ollama pull qwen2.5vl)
QWEN_VL_MODEL=qwen2.5vl

# HuggingFace model ID for Donut (receipt/invoice parsing)
DONUT_MODEL_ID=naver-clova-ix/donut-base-finetuned-cord-v2
# LayoutLM (when VISION_EXTRACTOR=layoutlm): token classification model for receipts
LAYOUTLM_MODEL_ID=nielsr/layoutlmv3-finetuned-cord
# Optional: HF token for faster Donut/LayoutLM download and higher rate limits (https://huggingface.co/settings/tokens)
HF_TOKEN=

# OCR engine: tesseract (default) | easyocr (requires pip install .[ocr])
OCR_ENGINE=tesseract

# Compare all extractors: set to 1 to run tesseract, easyocr, donut, qwen_vl per bill and add all_extractor_outputs to batch_output.json
OUTPUT_ALL_EXTRACTORS=0

# Thresholds
OCR_CONFIDENCE_THRESHOLD=0.6
DECISION_CONFIDENCE_THRESHOLD=0.7

# Retry
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY_SEC=2

# Policy: general
SUBMISSION_WINDOW_DAYS=90
# Max total reimbursable per employee per month (employee-level cap)
MONTHLY_TOTAL_CAP=6000.0

# Policy: meal / fuel / commute (loaded from policy PDF; uncomment only to override)
# MEAL_MAX_DAILY_LIMIT=50.0
# MEAL_MAX_MONTHLY_LIMIT=500.0
# FUEL_MAX_PER_KM_RATE=0.5
# FUEL_MONTHLY_CAP=300.0
# COMMUTE_MAX_PER_TRIP=25.0
# COMMUTE_MONTHLY_CAP=200.0

# Output directory (policy_allowances.json, batch_output.json, decisions.csv, audit_trail.log)
OUTPUT_DIR=test_output

# Output paths (relative to OUTPUT_DIR)
OUTPUT_JSON_PATH=batch_output.json
OUTPUT_CSV_PATH=decisions.csv
OUTPUT_DASHBOARD_PATH=dashboard_summary.json
OUTPUT_POLICY_PATH=policy_loaded.json
# Parallelism (1 = sequential; >1 = multiprocessing per expense folder)
MAX_WORKERS=1
# Logging
LOG_LEVEL=INFO
