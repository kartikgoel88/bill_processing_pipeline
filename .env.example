# Employee Reimbursement Processing Pipeline - Environment Example
# Copy to .env and fill in values

# Input (root folder with structure expense_type/employee_id/bills)
INPUT_ROOT=./test_input
# Optional: PDF to extract policy limits from (overrides defaults when present)
# POLICY_PDF_PATH=test_input/policy/company_policy.pdf
DRY_RUN=false

# LLM endpoint (default: local Ollama; or use https://api.openai.com/v1 for OpenAI)
LLM_BASE_URL=http://localhost:11434/v1
LLM_API_KEY=

# Optional: use different endpoints for vision vs decision (e.g. vision=OpenAI, decision=local)
# Leave unset to use LLM_BASE_URL and LLM_API_KEY for both
LLM_VISION_BASE_URL=
LLM_VISION_API_KEY=
LLM_DECISION_BASE_URL=
LLM_DECISION_API_KEY=

# Model names (Ollama: llava, llama3.2, qwen2.5:7b; OpenAI: gpt-4o-mini)
LLM_VISION_MODEL=llava
LLM_DECISION_MODEL=qwen2.5:7b

# Vision/document extraction: donut (default) | vision_llm | layoutlm
# donut = Donut model (no vision LLM; requires pip install -e ".[document]")
# vision_llm = legacy vision LLM (Ollama/OpenAI vision)
# layoutlm/layout = not implemented yet; falls back to donut
VISION_EXTRACTOR=layoutlm

# HuggingFace model ID for Donut (receipt/invoice parsing)
DONUT_MODEL_ID=naver-clova-ix/donut-base-finetuned-cord-v2
# LayoutLM (when VISION_EXTRACTOR=layoutlm): token classification model for receipts
LAYOUTLM_MODEL_ID=nielsr/layoutlmv3-finetuned-cord
# Optional: HF token for faster Donut/LayoutLM download and higher rate limits (https://huggingface.co/settings/tokens)
HF_TOKEN=

# Thresholds
OCR_CONFIDENCE_THRESHOLD=0.6
DECISION_CONFIDENCE_THRESHOLD=0.7

# Retry
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY_SEC=2

# Policy: general
SUBMISSION_WINDOW_DAYS=90
MONTHLY_TOTAL_CAP=6000.0

# Policy: meal / fuel / commute (loaded from policy PDF; uncomment only to override)
# MEAL_MAX_DAILY_LIMIT=50.0
# MEAL_MAX_MONTHLY_LIMIT=500.0
# FUEL_MAX_PER_KM_RATE=0.5
# FUEL_MONTHLY_CAP=300.0
# COMMUTE_MAX_PER_TRIP=25.0
# COMMUTE_MONTHLY_CAP=200.0

# Output directory (policy_allowances.json, batch_output.json, decisions.csv, audit_trail.log)
OUTPUT_DIR=test_output

# Output paths (relative to OUTPUT_DIR)
OUTPUT_JSON_PATH=batch_output.json
OUTPUT_CSV_PATH=decisions.csv
OUTPUT_DASHBOARD_PATH=dashboard_summary.json
# OUTPUT_POLICY_PATH=policy_loaded.json

# Parallelism (1 = sequential; >1 = multiprocessing per expense folder)
MAX_WORKERS=1

# Logging
LOG_LEVEL=INFO
