# =============================================================================
# Employee Reimbursement Processing Pipeline — Environment Example
# =============================================================================
# Copy to .env and set values. Uncomment only what you need to override.

# -----------------------------------------------------------------------------
# Input & run mode
# -----------------------------------------------------------------------------
# Root folder: expense_type/employee_id/bills (e.g. fuel/EMP001/, meal/EMP002/)
INPUT_ROOT=./test_input
# Policy PDF for --policy-allowances (extract allowances JSON)
# POLICY_PDF_PATH=test_input/policy/company_policy.pdf
DRY_RUN=false

# -----------------------------------------------------------------------------
# LLM — primary endpoint (used for both vision and decision if overrides unset)
# -----------------------------------------------------------------------------
# Must be OpenAI-compatible (POST .../chat/completions, response: choices[].message.content).
# Works: Ollama, OpenAI, Grok, or HF Inference Endpoints / proxies that speak that API.
# The default Hugging Face Inference API (api-inference.huggingface.co) is NOT compatible;
# for HF models use VISION_BACKEND=huggingface (local) or an OpenAI-compatible HF endpoint.
LLM_BASE_URL=http://localhost:11434/v1
LLM_API_KEY=

# -----------------------------------------------------------------------------
# LLM — optional: separate endpoints for vision vs decision
# -----------------------------------------------------------------------------
# Leave unset to use LLM_BASE_URL and LLM_API_KEY for both
# LLM_VISION_BASE_URL=
# LLM_VISION_API_KEY=
# LLM_DECISION_BASE_URL=
# LLM_DECISION_API_KEY=

# -----------------------------------------------------------------------------
# LLM — models
# -----------------------------------------------------------------------------
# Ollama examples: llava, llama3.2, qwen2.5:7b. OpenAI: gpt-4o-mini
LLM_VISION_MODEL=qwen_vl
LLM_DECISION_MODEL=qwen2.5:7b
# When VISION_EXTRACTOR=qwen_vl: model name (Ollama: ollama pull qwen2.5vl)
QWEN_VL_MODEL=qwen2.5vl

# -----------------------------------------------------------------------------
# Extraction — strategy and vision/document
# -----------------------------------------------------------------------------
# fusion = OCR + vision then fuse. vision_first = try vision first, OCR fallback
EXTRACTION_STRATEGY=vision_first
# donut | layoutlm | vision_llm | qwen_vl (donut/layoutlm need pip install -e ".[document]")
VISION_EXTRACTOR=qwen_vl
# When VISION_EXTRACTOR=qwen_vl: ollama | huggingface (local) | hf_api (hosted HF Inference API)
# VISION_BACKEND=ollama          — use Ollama/OpenAI-compatible API (QWEN_VL_MODEL)
# VISION_BACKEND=huggingface     — run Qwen-VL locally (pip install -e ".[document]")
# VISION_BACKEND=hf_api          — use Hugging Face Inference API (no local download); set HF_TOKEN
VISION_BACKEND=hf_api
# Hugging Face model for Qwen-VL when VISION_BACKEND=huggingface or hf_api
QWEN_VL_HF_MODEL=Qwen/Qwen2.5-VL-7B-Instruct
# Required for VISION_BACKEND=hf_api; optional for Donut/LayoutLM downloads
HF_TOKEN=
# HuggingFace model IDs (Donut / LayoutLM)
DONUT_MODEL_ID=naver-clova-ix/donut-base-finetuned-cord-v2
LAYOUTLM_MODEL_ID=nielsr/layoutlmv3-finetuned-cord

# -----------------------------------------------------------------------------
# OCR
# -----------------------------------------------------------------------------
# tesseract (default) | easyocr (pip install .[ocr])
OCR_ENGINE=tesseract

# -----------------------------------------------------------------------------
# Extractors comparison (optional)
# -----------------------------------------------------------------------------
# Set to 1 to run tesseract, easyocr, donut, qwen_vl per bill; add all_extractor_outputs to batch_output.json
OUTPUT_ALL_EXTRACTORS=0

# -----------------------------------------------------------------------------
# Thresholds & retry
# -----------------------------------------------------------------------------
OCR_CONFIDENCE_THRESHOLD=0.6
DECISION_CONFIDENCE_THRESHOLD=0.7
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY_SEC=2

# -----------------------------------------------------------------------------
# Policy — general (allowances are usually loaded from policy PDF)
# -----------------------------------------------------------------------------
SUBMISSION_WINDOW_DAYS=90
# Max reimbursable per employee per month (employee-level cap)
MONTHLY_TOTAL_CAP=6000.0
# Override allowances only if not using policy PDF (normally leave commented)
# MEAL_MAX_DAILY_LIMIT=50.0
# MEAL_MAX_MONTHLY_LIMIT=500.0
# FUEL_MAX_PER_KM_RATE=0.5
# FUEL_MONTHLY_CAP=300.0
# COMMUTE_MAX_PER_TRIP=25.0
# COMMUTE_MONTHLY_CAP=200.0

# -----------------------------------------------------------------------------
# Output — directory and file names (paths relative to OUTPUT_DIR)
# -----------------------------------------------------------------------------
OUTPUT_DIR=test_output
OUTPUT_JSON_PATH=batch_output.json
OUTPUT_CSV_PATH=decisions.csv
OUTPUT_DASHBOARD_PATH=dashboard_summary.json
OUTPUT_POLICY_PATH=policy_loaded.json
# Policy allowances pipeline output (--policy-allowances)
# POLICY_ALLOWANCES_OUTPUT_PATH=policy_allowances.json
# POLICY_ALLOWANCES_PROMPT_PATH=prompts/system_prompt_policy_allowances.txt
AUDIT_LOG_PATH=audit_trail.log
# POLICY_CACHE_PATH=policy_cache.json
# POLICY_VERSION_HASH_PATH=policy_version_hash.txt

# -----------------------------------------------------------------------------
# Parallelism & logging
# -----------------------------------------------------------------------------
# 1 = sequential; >1 = multiprocessing per expense-type folder
MAX_WORKERS=1
LOG_LEVEL=INFO
